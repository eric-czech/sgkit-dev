{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glow\n",
    "from glow import linear_regression_gwas, expand_struct\n",
    "import numpy as np\n",
    "from pyspark.ml.linalg import DenseMatrix\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .config('spark.jars.packages', 'io.projectglow:glow_2.11:0.5.0')\\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\\\n",
    "    .getOrCreate()\n",
    "glow.register(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "g = np.array([0., 1., 2., 0.])\n",
    "x = np.array([\n",
    "    [1, -1],\n",
    "    [2, -2],\n",
    "    [3, -3],\n",
    "    [4, -4.],\n",
    "])\n",
    "b = np.array([0., 1.])\n",
    "y = g + np.dot(x, b) + np.random.normal(scale=.01, size=g.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -0.]\n",
      " [ 1. -1.]\n",
      " [ 2. -2.]\n",
      " [ 3. -3.]]\n",
      "Row(i=0, x=DenseMatrix(4, 2, [0.0, -0.0, 1.0, -1.0, 2.0, -2.0, 3.0, -3.0], False))\n",
      "[[ 0.  2.]\n",
      " [-0. -2.]\n",
      " [ 1.  3.]\n",
      " [-1. -3.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "x = np.column_stack([np.arange(4), -np.arange(4, dtype=float)])\n",
    "print(x)\n",
    "r = spark.createDataFrame(pd.DataFrame({'i': [0]})).withColumn('x', F.lit(x)).limit(1).collect()[0]\n",
    "print(r)\n",
    "print(r.x.toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 4.],\n",
       "       [1., 5.],\n",
       "       [2., 6.],\n",
       "       [3., 7.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.x.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+--------------------+\n",
      "|              beta|      standardError|              pValue|\n",
      "+------------------+-------------------+--------------------+\n",
      "|-2.382793056158103|0.20221757585071454|0.053898082087957454|\n",
      "+------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame([Row(genotypes=g.tolist(), phenotypes=y.tolist())])\\\n",
    "    .select(expand_struct(linear_regression_gwas('genotypes', 'phenotypes', F.lit(np.asfortranarray(x)))))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Version 1\n",
      "[[ 1. -1.]\n",
      " [ 2. -2.]\n",
      " [ 3. -3.]\n",
      " [ 4. -4.]]\n",
      "+------------------+--------------------+--------------------+\n",
      "|              beta|       standardError|              pValue|\n",
      "+------------------+--------------------+--------------------+\n",
      "|0.9948866298677059|0.001300287478677...|8.320427901051293E-4|\n",
      "+------------------+--------------------+--------------------+\n",
      "\n",
      "--------------------------------------------------\n",
      "Version 2\n",
      "[[ 1.  3.]\n",
      " [-1. -3.]\n",
      " [ 2.  4.]\n",
      " [-2. -4.]]\n",
      "+------------------+-------------------+--------------------+\n",
      "|              beta|      standardError|              pValue|\n",
      "+------------------+-------------------+--------------------+\n",
      "|-2.382793056158103|0.20221757585071454|0.053898082087957454|\n",
      "+------------------+-------------------+--------------------+\n",
      "\n",
      "--------------------------------------------------\n",
      "Version 3\n",
      "+------------------+-------------------+--------------------+\n",
      "|              beta|      standardError|              pValue|\n",
      "+------------------+-------------------+--------------------+\n",
      "|-2.382793056158103|0.20221757585071454|0.053898082087957454|\n",
      "+------------------+-------------------+--------------------+\n",
      "\n",
      "--------------------------------------------------\n",
      "Version 4\n",
      "[[ 1.  2.]\n",
      " [ 3.  4.]\n",
      " [-1. -2.]\n",
      " [-3. -4.]]\n",
      "+------------------+--------------------+--------------------+\n",
      "|              beta|       standardError|              pValue|\n",
      "+------------------+--------------------+--------------------+\n",
      "|0.9948866298677059|0.001300287478677...|8.320427901051293E-4|\n",
      "+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HR = '-' * 50\n",
    "print(HR)\n",
    "print('Version 1')\n",
    "# Correct version\n",
    "dm = DenseMatrix(numRows=x.shape[0], numCols=x.shape[1], values=x.ravel(order='F').tolist())\n",
    "np.testing.assert_equal(x, dm.toArray())\n",
    "print(dm.toArray())\n",
    "spark.createDataFrame([Row(genotypes=g.tolist(), phenotypes=y.tolist(), covariates=dm)])\\\n",
    "    .select(expand_struct(linear_regression_gwas('genotypes', 'phenotypes', 'covariates')))\\\n",
    "    .show()\n",
    "\n",
    "print(HR)\n",
    "print('Version 2')\n",
    "# Version also like demo notebook with explicit matrix field (also wrong)\n",
    "dm = DenseMatrix(numRows=x.shape[0], numCols=x.shape[1], values=x.ravel(order='C').tolist())\n",
    "print(dm.toArray())\n",
    "spark.createDataFrame([Row(genotypes=g.tolist(), phenotypes=y.tolist(), covariates=dm)])\\\n",
    "    .select(expand_struct(linear_regression_gwas('genotypes', 'phenotypes', 'covariates')))\\\n",
    "    .show()\n",
    "\n",
    "print(HR)\n",
    "print('Version 3')\n",
    "# Version like demo notebook (wrong)\n",
    "spark.createDataFrame([Row(genotypes=g.tolist(), phenotypes=y.tolist())])\\\n",
    "    .select(expand_struct(linear_regression_gwas('genotypes', 'phenotypes', F.lit(x))))\\\n",
    "    .show()\n",
    "\n",
    "print(HR)\n",
    "print('Version 4')\n",
    "# Correct version using numpy literal column\n",
    "x_weird = x.T.ravel(order='C').reshape(x.shape)\n",
    "print(x_weird)\n",
    "spark.createDataFrame([Row(genotypes=g.tolist(), phenotypes=y.tolist())])\\\n",
    "    .select(expand_struct(linear_regression_gwas('genotypes', 'phenotypes', F.lit(x_weird))))\\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hail",
   "language": "python",
   "name": "hail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
